{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11cc3e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in e:\\users\\hp elitebook 810 g3\\anaconda3\\lib\\site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1deff797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a512acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4abd99e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4cd53bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(iris_df.data,iris_df.target,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c8ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines Creations\n",
    "# 1) data Preprocessing by using Standard Scaler\n",
    "# 2) Reduce dimension using PCA\n",
    "# 3) Apply Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98dfb5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr=Pipeline([('scalar1',StandardScaler()),\n",
    "                     ('pca1',PCA(n_components=2)),\n",
    "                     ('lr_classifier',LogisticRegression(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f35ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dt=Pipeline([('scalar2',StandardScaler()),\n",
    "                     ('pca2',PCA(n_components=2)),\n",
    "                     ('dt_classifier',DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c14fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_randomforest=Pipeline([('scalar3',StandardScaler()),\n",
    "                     ('pca3',PCA(n_components=2)),\n",
    "                     ('rf_classifier',RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9ce19b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of Pipelines\n",
    "pipelines = [pipeline_lr, pipeline_dt, pipeline_randomforest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97267c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy=0.0\n",
    "best_classifier=0\n",
    "best_pipeline=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c606407",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dict= {0:'Logistic Regression', 1: 'Decision Tree', 2: 'RandomForest'}\n",
    "\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed5935ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.9111111111111111\n",
      "Decision Tree Test Accuracy: 0.9555555555555556\n",
      "RandomForest Test Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    print('{} Test Accuracy: {}'.format(pipe_dict[i],model.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4316669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier with best accuracy:Decision Tree\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(x_test,y_test)>best_accuracy:\n",
    "        best_accuracy=model.score(x_test,y_test)\n",
    "        best_pipeline=model\n",
    "        best_classifier=i\n",
    "print('Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef44fcc4",
   "metadata": {},
   "source": [
    "### Pipeline Perform Hyperparameter Tuning Using Grid SearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cf2d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08d5477f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\HP ELITEBOOK 810 G3\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "50 fits failed out of a total of 1920.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Users\\HP ELITEBOOK 810 G3\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Users\\HP ELITEBOOK 810 G3\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"E:\\Users\\HP ELITEBOOK 810 G3\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\Users\\HP ELITEBOOK 810 G3\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "E:\\Users\\HP ELITEBOOK 810 G3\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.96190476        nan 0.95238095        nan 0.94285714\n",
      "        nan 0.94285714        nan 0.95238095        nan 0.95238095\n",
      "        nan 0.95238095        nan 0.95238095        nan 0.95238095\n",
      "        nan 0.95238095 0.96190476 0.96190476 0.97142857 0.94285714\n",
      " 0.95238095 0.96190476 0.96190476 0.94285714 0.94285714 0.95238095\n",
      " 0.96190476 0.95238095 0.94285714 0.96190476 0.96190476 0.94285714\n",
      " 0.95238095 0.96190476 0.96190476 0.95238095 0.95238095 0.96190476\n",
      " 0.96190476 0.95238095 0.95238095 0.96190476 0.96190476 0.95238095\n",
      " 0.95238095 0.96190476 0.96190476 0.94285714 0.95238095 0.96190476\n",
      " 0.96190476 0.94285714 0.95238095 0.96190476 0.96190476 0.94285714\n",
      " 0.93333333 0.94285714 0.93333333 0.91428571 0.94285714 0.93333333\n",
      " 0.8952381  0.93333333 0.93333333 0.92380952 0.92380952 0.94285714\n",
      " 0.84761905 0.93333333 0.94285714 0.35238095 0.33333333 0.33333333\n",
      " 0.93333333 0.94285714 0.94285714 0.92380952 0.93333333 0.94285714\n",
      " 0.92380952 0.94285714 0.94285714 0.92380952 0.93333333 0.93333333\n",
      " 0.92380952 0.91428571 0.93333333 0.35238095 0.33333333 0.33333333\n",
      " 0.95238095 0.93333333 0.94285714 0.93333333 0.93333333 0.93333333\n",
      " 0.94285714 0.93333333 0.94285714 0.93333333 0.92380952 0.93333333\n",
      " 0.94285714 0.93333333 0.94285714 0.35238095 0.34285714 0.33333333\n",
      " 0.79047619 0.94285714 0.93333333 0.86666667 0.92380952 0.94285714\n",
      " 0.86666667 0.93333333 0.95238095 0.94285714 0.95238095 0.94285714\n",
      " 0.8952381  0.94285714 0.94285714 0.35238095 0.33333333 0.33333333\n",
      " 0.95238095 0.94285714 0.94285714 0.94285714 0.93333333 0.93333333\n",
      " 0.92380952 0.94285714 0.93333333 0.93333333 0.95238095 0.93333333\n",
      " 0.92380952 0.92380952 0.93333333 0.34285714 0.34285714 0.33333333\n",
      " 0.93333333 0.94285714 0.94285714 0.94285714 0.94285714 0.93333333\n",
      " 0.94285714 0.93333333 0.93333333 0.92380952 0.93333333 0.93333333\n",
      " 0.93333333 0.94285714 0.93333333 0.34285714 0.33333333 0.33333333\n",
      " 0.94285714 0.94285714 0.94285714 0.93333333 0.94285714 0.94285714\n",
      " 0.85714286 0.93333333 0.94285714 0.94285714 0.94285714 0.94285714\n",
      " 0.93333333 0.92380952 0.94285714 0.35238095 0.34285714 0.33333333\n",
      " 0.94285714 0.94285714 0.94285714 0.93333333 0.95238095 0.93333333\n",
      " 0.92380952 0.93333333 0.93333333 0.93333333 0.93333333 0.93333333\n",
      " 0.94285714 0.93333333 0.93333333 0.35238095 0.33333333 0.33333333\n",
      " 0.93333333 0.94285714 0.94285714 0.95238095 0.93333333 0.93333333\n",
      " 0.94285714 0.94285714 0.93333333 0.93333333 0.94285714 0.93333333\n",
      " 0.93333333 0.95238095 0.93333333 0.34285714 0.34285714 0.33333333\n",
      " 0.92380952 0.92380952 0.93333333 0.83809524 0.94285714 0.93333333\n",
      " 0.83809524 0.92380952 0.93333333 0.8        0.92380952 0.94285714\n",
      " 0.92380952 0.93333333 0.94285714 0.34285714 0.34285714 0.33333333\n",
      " 0.92380952 0.94285714 0.94285714 0.94285714 0.94285714 0.93333333\n",
      " 0.92380952 0.93333333 0.93333333 0.94285714 0.93333333 0.93333333\n",
      " 0.94285714 0.93333333 0.93333333 0.36190476 0.33333333 0.33333333\n",
      " 0.94285714 0.93333333 0.94285714 0.91428571 0.93333333 0.93333333\n",
      " 0.93333333 0.94285714 0.93333333 0.94285714 0.94285714 0.93333333\n",
      " 0.92380952 0.93333333 0.93333333 0.35238095 0.33333333 0.33333333\n",
      " 0.93333333 0.92380952 0.94285714 0.88571429 0.92380952 0.94285714\n",
      " 0.85714286 0.93333333 0.93333333 0.91428571 0.91428571 0.93333333\n",
      " 0.88571429 0.93333333 0.94285714 0.34285714 0.33333333 0.33333333\n",
      " 0.92380952 0.94285714 0.94285714 0.94285714 0.94285714 0.93333333\n",
      " 0.93333333 0.93333333 0.93333333 0.93333333 0.94285714 0.93333333\n",
      " 0.94285714 0.93333333 0.93333333 0.36190476 0.34285714 0.33333333\n",
      " 0.93333333 0.94285714 0.94285714 0.94285714 0.93333333 0.93333333\n",
      " 0.93333333 0.94285714 0.93333333 0.94285714 0.93333333 0.93333333\n",
      " 0.93333333 0.94285714 0.93333333 0.35238095 0.33333333 0.33333333\n",
      " 0.80952381 0.93333333 0.93333333 0.8952381  0.93333333 0.93333333\n",
      " 0.81904762 0.95238095 0.93333333 0.85714286 0.93333333 0.93333333\n",
      " 0.88571429 0.95238095 0.94285714 0.35238095 0.33333333 0.33333333\n",
      " 0.93333333 0.93333333 0.94285714 0.93333333 0.94285714 0.93333333\n",
      " 0.94285714 0.94285714 0.93333333 0.94285714 0.93333333 0.93333333\n",
      " 0.94285714 0.94285714 0.94285714 0.36190476 0.35238095 0.33333333\n",
      " 0.94285714 0.95238095 0.94285714 0.94285714 0.94285714 0.93333333\n",
      " 0.94285714 0.94285714 0.93333333 0.95238095 0.93333333 0.93333333\n",
      " 0.93333333 0.93333333 0.94285714 0.35238095 0.33333333 0.33333333]\n",
      "  warnings.warn(\n",
      "E:\\Users\\HP ELITEBOOK 810 G3\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# create a Pipeline\n",
    "pipe = Pipeline([(\"classifier\",RandomForestClassifier())])\n",
    "grid_param = [\n",
    "    {\"classifier\":[LogisticRegression()],\n",
    "    \"classifier__penalty\": ['l1','l2'],\n",
    "    \"classifier__C\": np.logspace(0,4,10)\n",
    "    },\n",
    "    {\"classifier\": [LogisticRegression()],\n",
    "     \"classifier__penalty\": ['l2'],\n",
    "     \"classifier__C\":np.logspace(0,4,10),\n",
    "     \"classifier__solver\":['newton-cg','saga','sag','liblinear']\n",
    "    },\n",
    "    {\"classifier\":[RandomForestClassifier()],\n",
    "     \"classifier__n_estimators\":[10,100,1000],\n",
    "     \"classifier__max_depth\":[5,8,15,25,30,None],\n",
    "     \"classifier__min_samples_leaf\":[1,2,5,10,15,100],\n",
    "     \"classifier__max_leaf_nodes\":[2,10,5]}]\n",
    "\n",
    "gridsearch = GridSearchCV(pipe,grid_param,cv=5,verbose=0,n_jobs=-1)\n",
    "best_model = gridsearch.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0db7e139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('classifier', LogisticRegression(solver='sag'))])\n",
      "The mean accuracy of the model is: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(best_model.best_estimator_)\n",
    "print(\"The mean accuracy of the model is:\",best_model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be1d289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
